{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/envs/hackathon/lib/python3.7/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import speech_recognition as sr \n",
    "\n",
    "from sys import argv  \n",
    "from pydub import AudioSegment, effects\n",
    "from pydub.silence import split_on_silence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalization():\n",
    "    '''\n",
    "    to normalize the audio pitch inside the audio file\n",
    "    \n",
    "    input: will take thepath of audio file in .wav form as input\n",
    "    output: will normalize the audio and save it as normalized.wav\n",
    "    '''\n",
    "    \n",
    "    file = input('Enter the path to recorded file')\n",
    "    rawsound = AudioSegment.from_file(file, \"wav\")  \n",
    "    normalizedsound = effects.normalize(rawsound)  \n",
    "    normalizedsound.export(\"normalized.wav\", format=\"wav\")\n",
    "    print(\"normalized recording saved as normalized.wav \\n\")\n",
    "\n",
    "def speechToTextModule(lang=\"en-in\"):\n",
    "    '''\n",
    "    to convert audio file to text\n",
    "    brief: It will firstly normalize the audion after that on the basis of silence\n",
    "    and frecuence will cut the audio into segments and then it will process \n",
    "    each chunk of audio and convert to text. \n",
    "    \n",
    "    input: will take thepath of audio file in .wav form as input\n",
    "    output: recognized.txt file with all text converted\n",
    "    '''\n",
    "    # calling normalization function\n",
    "    normalization()\n",
    "    \n",
    "    # opening normalized audio file and recognized.txt for appending detected text\n",
    "    song = AudioSegment.from_wav(\"normalized.wav\") \n",
    "    fh = open(\"recognized.txt\", \"w+\") \n",
    "          \n",
    "    # spliting audio into chunks with parameter as silence of 1.2 seconds  \n",
    "    chunks = split_on_silence(song, \n",
    "        # must be silent for at least 1.2 seconds \n",
    "        min_silence_len = 1200, \n",
    "        # consider it silent if quieter than -50 dBFS \n",
    "        silence_thresh = -50\n",
    "    ) \n",
    "  \n",
    "    # creating a directory to store the audio chunks. \n",
    "    try: \n",
    "        os.mkdir('audio_chunks') \n",
    "    except(FileExistsError): \n",
    "        pass\n",
    "    \n",
    "    print(\"folder created for storing the chunks of audio file \\n\")\n",
    "\n",
    "\n",
    "    os.chdir('audio_chunks') \n",
    "  \n",
    "    i = 0\n",
    "    # processing  each chunk \n",
    "    for chunk in chunks: \n",
    "              \n",
    "        # Create 0.5 seconds silence chunk \n",
    "        chunk_silent = AudioSegment.silent(duration = 10) \n",
    "   \n",
    "        audio_chunk = chunk_silent + chunk + chunk_silent \n",
    "  \n",
    "        # export audio chunk and save it in the current directory. \n",
    "        print(\"saving chunk{0}.wav\".format(i)) \n",
    "        \n",
    "        # specify the bitrate to be 192 k \n",
    "        audio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\") \n",
    "  \n",
    "        # the name of the newly created chunk \n",
    "        filename = 'chunk'+str(i)+'.wav'\n",
    "  \n",
    "        print(\"Processing chunk \"+str(i)) \n",
    "  \n",
    "        # get the name of the newly created chunk \n",
    "        # in the AUDIO_FILE variable for later use. \n",
    "        file = filename \n",
    "  \n",
    "        # create a speech recognition object \n",
    "        r = sr.Recognizer() \n",
    "  \n",
    "        # recognize the chunk \n",
    "        with sr.AudioFile(file) as source:  \n",
    "            r.pause_threshhold = 1\n",
    "            r.energy_threshold = 7000\n",
    "            audio_listened = r.listen(source)\n",
    "            # below could be used in case above three lines are not giving good results \n",
    "            # r.adjust_for_ambient_noise(source) \n",
    "            # audio_listened = r.listen(source) \n",
    "            \n",
    "        try: \n",
    "            # try converting it to text by specifying the language\n",
    "            rec = r.recognize_google(audio_listened, language=lang) \n",
    "            # write the output to the file. \n",
    "            fh.write(rec+\". \") \n",
    "  \n",
    "        # catch any errors. \n",
    "        except sr.UnknownValueError: \n",
    "            print(\"Could not understand audio\") \n",
    "  \n",
    "        except sr.RequestError as e: \n",
    "            print(\"no internet connection or access\") \n",
    "  \n",
    "        i += 1\n",
    "  \n",
    "    os.chdir('..') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speechToTextModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
